{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T09:28:59.979446224Z",
     "start_time": "2025-12-15T09:28:58.187482758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=1000,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ],
   "id": "82213c2eac922d61",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-15T09:29:01.210059797Z",
     "start_time": "2025-12-15T09:28:59.979980707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorrt as trt\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# === загрузка engine и создание контекста ===\n",
    "def load_trt_context(engine_path: str):\n",
    "    with open(engine_path, \"rb\") as f:\n",
    "        runtime = trt.Runtime(logger)\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "    return engine, context\n",
    "\n",
    "def trt_dtype_to_torch(dt: trt.DataType):\n",
    "    if dt == trt.DataType.FLOAT:  return torch.float32\n",
    "    if dt == trt.DataType.HALF:   return torch.float16\n",
    "    if dt == trt.DataType.INT32:  return torch.int32\n",
    "    if dt == trt.DataType.BOOL:   return torch.bool\n",
    "    raise NotImplementedError(dt)\n",
    "\n",
    "def get_io_names(engine: trt.ICudaEngine):\n",
    "    inputs, outputs = [], []\n",
    "    for i in range(engine.num_io_tensors):\n",
    "        name = engine.get_tensor_name(i)\n",
    "        mode = engine.get_tensor_mode(name)\n",
    "        if mode == trt.TensorIOMode.INPUT:\n",
    "            inputs.append(name)\n",
    "        elif mode == trt.TensorIOMode.OUTPUT:\n",
    "            outputs.append(name)\n",
    "    if len(inputs) != 1 or len(outputs) != 1:\n",
    "        raise RuntimeError(f\"Ожидал 1 вход и 1 выход, получил {len(inputs)} / {len(outputs)}\")\n",
    "    return inputs[0], outputs[0]\n",
    "\n",
    "# --- только forward (engine-only): данные уже на GPU ---\n",
    "def trt_forward_only(engine, context, input_name, output_name, images_cuda: torch.Tensor):\n",
    "    # привести dtype входа при необходимости\n",
    "    want_dtype = trt_dtype_to_torch(engine.get_tensor_dtype(input_name))\n",
    "    if images_cuda.dtype != want_dtype:\n",
    "        images_cuda = images_cuda.to(want_dtype)\n",
    "\n",
    "    # задать форму входа и подготовить выход\n",
    "    context.set_input_shape(input_name, tuple(images_cuda.shape))\n",
    "    out_shape = tuple(context.get_tensor_shape(output_name))\n",
    "    if any(d == -1 for d in out_shape):\n",
    "        out_shape = (images_cuda.shape[0], out_shape[-1])\n",
    "    out_dtype = trt_dtype_to_torch(engine.get_tensor_dtype(output_name))\n",
    "    logits = torch.empty(out_shape, device=\"cuda\", dtype=out_dtype)\n",
    "\n",
    "    # проброс указателей\n",
    "    context.set_tensor_address(input_name,  images_cuda.data_ptr())\n",
    "    context.set_tensor_address(output_name, logits.data_ptr())\n",
    "\n",
    "    # тайминг строго вокруг execute_async_v3\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    ok = context.execute_async_v3(torch.cuda.current_stream().cuda_stream)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"execute_async_v3 failed\")\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.perf_counter()\n",
    "    return logits, (t1 - t0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_trt_like_pytorch(engine_path: str, test_loader, warmup_batches=5, tag=\"TensorRT\"):\n",
    "    engine, context = load_trt_context(engine_path)\n",
    "    input_name, output_name = get_io_names(engine)\n",
    "\n",
    "    total = correct = 0\n",
    "    run_loss = 0.0\n",
    "\n",
    "    # усреднения\n",
    "    fwd_sum = 0.0     # только engine\n",
    "    e2e_sum = 0.0     # H2D -> engine -> sync\n",
    "    measured = 0\n",
    "    bs_seen = None\n",
    "\n",
    "    for bi, (images_cpu, labels_cpu) in enumerate(test_loader):\n",
    "        # --- e2e: копия на GPU + execute + sync ---\n",
    "        torch.cuda.synchronize()\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        images = images_cpu.to(\"cuda\", non_blocking=True)\n",
    "        logits, _ = trt_forward_only(engine, context, input_name, output_name, images)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "        e2e_dt = t1 - t0\n",
    "\n",
    "        # --- forward-only: данные уже на GPU ---\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.perf_counter()\n",
    "        _ = trt_forward_only(engine, context, input_name, output_name, images)\n",
    "        torch.cuda.synchronize()\n",
    "        t3 = time.perf_counter()\n",
    "        fwd_dt = t3 - t2\n",
    "\n",
    "        labels = labels_cpu.to(\"cuda\", non_blocking=True)\n",
    "        loss = criterion(logits.float(), labels)  # на всякий случай к fp32\n",
    "        run_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        if bs_seen is None:\n",
    "            bs_seen = labels.size(0)\n",
    "\n",
    "        if bi >= warmup_batches:\n",
    "            fwd_sum += fwd_dt\n",
    "            e2e_sum += e2e_dt\n",
    "            measured += 1\n",
    "\n",
    "    loss = run_loss / total\n",
    "    acc = correct / total\n",
    "\n",
    "    if measured > 0 and bs_seen:\n",
    "        fwd_t_batch = fwd_sum / measured\n",
    "        fwd_t_img   = fwd_t_batch / bs_seen\n",
    "        fwd_fps     = 1.0 / fwd_t_img\n",
    "\n",
    "        e2e_t_batch = e2e_sum / measured\n",
    "        e2e_t_img   = e2e_t_batch / bs_seen\n",
    "        e2e_fps     = 1.0 / e2e_t_img\n",
    "    else:\n",
    "        fwd_t_batch = fwd_t_img = fwd_fps = float(\"nan\")\n",
    "        e2e_t_batch = e2e_t_img = e2e_fps = float(\"nan\")\n",
    "\n",
    "    print(\n",
    "        f\"{tag}: loss={loss:.4f} acc={acc:.4f} | \"\n",
    "        f\"forward: {fwd_t_batch*1000:.3f} ms/batch, {fwd_t_img*1000:.4f} ms/img, {fwd_fps:.1f} FPS | \"\n",
    "        f\"e2e: {e2e_t_batch*1000:.3f} ms/batch, {e2e_t_img*1000:.4f} ms/img, {e2e_fps:.1f} FPS\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss, \"acc\": acc,\n",
    "        \"fwd_batch_s\": fwd_t_batch, \"fwd_img_s\": fwd_t_img, \"fwd_fps\": fwd_fps,\n",
    "        \"e2e_batch_s\": e2e_t_batch, \"e2e_img_s\": e2e_t_img, \"e2e_fps\": e2e_fps,\n",
    "    }\n",
    "\n",
    "# Пример:\n",
    "stats_fp16 = evaluate_trt_like_pytorch(\"lenet_cifar10_fp16.trt\", test_loader, tag=\"TensorRT FP16\")\n",
    "stats_fp32 = evaluate_trt_like_pytorch(\"lenet_cifar10_fp32.trt\", test_loader, tag=\"TensorRT FP32\")\n"
   ],
   "id": "f2debf5acfc7ff3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/15/2025-12:29:00] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "TensorRT FP16: loss=0.7994 acc=0.7270 | forward: 0.704 ms/batch, 0.0007 ms/img, 1419851.1 FPS | e2e: 1.670 ms/batch, 0.0017 ms/img, 598672.3 FPS\n",
      "[12/15/2025-12:29:00] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "TensorRT FP32: loss=0.7995 acc=0.7268 | forward: 0.752 ms/batch, 0.0008 ms/img, 1330121.2 FPS | e2e: 1.498 ms/batch, 0.0015 ms/img, 667438.0 FPS\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T09:29:01.217185105Z",
     "start_time": "2025-12-15T09:29:01.212654636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import tensorrt as trt\n",
    "#\n",
    "# def build_engine_from_onnx(onnx_path: str, engine_path: str, fp16: bool = False):\n",
    "#     logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "#     trt.init_libnvinfer_plugins(logger, \"\")\n",
    "#\n",
    "#     builder = trt.Builder(logger)\n",
    "#     network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "#     parser = trt.OnnxParser(network, logger)\n",
    "#\n",
    "#     with open(onnx_path, \"rb\") as f:\n",
    "#         if not parser.parse(f.read()):\n",
    "#             msgs = \"\\n\".join(str(parser.get_error(i)) for i in range(parser.num_errors))\n",
    "#             raise RuntimeError(\"ONNX parse failed:\\n\" + msgs)\n",
    "#\n",
    "#     config = builder.create_builder_config()\n",
    "#     config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB\n",
    "#\n",
    "#     if fp16:\n",
    "#         config.set_flag(trt.BuilderFlag.FP16)\n",
    "#\n",
    "#     # Если входы динамические, здесь нужно добавить optimization profile.\n",
    "#     # (Для фиксированного LeNet можно не делать.)\n",
    "#\n",
    "#     serialized = builder.build_serialized_network(network, config)\n",
    "#     if serialized is None:\n",
    "#         raise RuntimeError(\"build_serialized_network вернул None (не смог собрать engine).\")\n",
    "#\n",
    "#     with open(engine_path, \"wb\") as f:\n",
    "#         f.write(serialized)\n",
    "#\n",
    "# build_engine_from_onnx(\"lenet_cifar10.onnx\", \"lenet_cifar10_fp32.trt\", fp16=False)\n",
    "# build_engine_from_onnx(\"lenet_cifar10.onnx\", \"lenet_cifar10_fp16.trt\", fp16=True)\n"
   ],
   "id": "838c5600572c35d4",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
