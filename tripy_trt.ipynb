{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T09:48:38.584551413Z",
     "start_time": "2025-12-15T09:48:37.622380834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=1000,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ],
   "id": "9f345b781e239cc3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-15T09:48:38.715470309Z",
     "start_time": "2025-12-15T09:48:38.585031273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import nvtripy as tp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class TripyLeNet(tp.Module):\n",
    "    def __init__(self, dtype=tp.float32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = tp.Conv(\n",
    "            in_channels=3,\n",
    "            out_channels=6,\n",
    "            kernel_dims=(5, 5),\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.conv2 = tp.Conv(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_dims=(5, 5),\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "        self.fc1 = tp.Linear(16 * 5 * 5, 120, dtype=dtype)\n",
    "        self.fc2 = tp.Linear(120, 84, dtype=dtype)\n",
    "        self.out = tp.Linear(84, 10, dtype=dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # вход: (N, 3, 32, 32)\n",
    "        x = self.conv1(x)\n",
    "        x = tp.relu(x)\n",
    "        x = tp.maxpool(x, kernel_dims=(2, 2), stride=(2, 2))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = tp.relu(x)\n",
    "        x = tp.maxpool(x, kernel_dims=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # выпрямление фичей: (N, 16*5*5)\n",
    "        x = tp.reshape(x, (x.shape[0], -1))\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = tp.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = tp.relu(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def convert_state_torch_to_tripy(torch_state):\n",
    "    tripy_state = {}\n",
    "    for name, param in torch_state.items():\n",
    "        np_value = param.detach().cpu().numpy().astype(\"float32\")\n",
    "        tripy_state[name] = tp.Tensor(np_value)\n",
    "    return tripy_state\n",
    "\n",
    "def to_tripy_tensor(x_torch):\n",
    "    list_x = x_torch.tolist()\n",
    "    return tp.Tensor(list_x)\n",
    "\n",
    "def to_torch_tensor(x_tripy):\n",
    "    list_x = x_tripy.tolist()\n",
    "    return torch.Tensor(list_x)\n",
    "\n",
    "torch_state = torch.load(\"lenet_cifar10_best_pytorch.pth\")\n",
    "tripy_state = convert_state_torch_to_tripy(torch_state)\n",
    "\n",
    "tripy_model = TripyLeNet()\n",
    "tripy_model.load_state_dict(tripy_state)\n",
    "# GEGLU has one parameter, which needs to be a runtime input:\n",
    "inp_info = tp.InputInfo(shape=(1000, 3, 32, 32), dtype=tp.float32)\n",
    "fast_model = tp.compile(tripy_model, args=[inp_info])"
   ],
   "id": "da163b1e8aa52f8e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING The logger passed into createInferRuntime differs from one already registered for an existing builder, runtime, or refitter. So the current new logger is ignored, and TensorRT will use the existing one which is returned by nvinfer1::getLogger() instead.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T09:48:39.427446285Z",
     "start_time": "2025-12-15T09:48:38.715925081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "import nvtripy as tp\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_tripy_time(exe, test_loader, warmup_batches=5, device=\"cuda\", fp16=False):\n",
    "    \"\"\"\n",
    "    Замеры:\n",
    "      - e2e: H2D -> wrap -> forward -> sync\n",
    "      - fwd: forward-only (данные уже на GPU) -> sync\n",
    "    Без loss/acc.\n",
    "    \"\"\"\n",
    "    if device != \"cuda\":\n",
    "        raise ValueError(\"Для бенча ожидается device='cuda'.\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA недоступна.\")\n",
    "\n",
    "    fwd_time_sum = 0.0\n",
    "    e2e_time_sum = 0.0\n",
    "    measured = 0\n",
    "    bs_seen = None\n",
    "\n",
    "    for bi, (images_cpu, _) in enumerate(test_loader):\n",
    "        # --- end-to-end замер ---\n",
    "        torch.cuda.synchronize()\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        images = images_cpu.to(device, non_blocking=True)\n",
    "        if fp16:\n",
    "            images = images.half()\n",
    "        images = images.contiguous()\n",
    "\n",
    "        images_tp = tp.Tensor(images).eval()   # гарантируем, что вход \"готов\"\n",
    "        _ = exe(images_tp).eval()              # гарантируем, что инференс выполнен\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "        e2e_dt = t1 - t0\n",
    "\n",
    "        # --- forward-only замер (данные уже на GPU) ---\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.perf_counter()\n",
    "\n",
    "        _ = exe(images_tp).eval()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t3 = time.perf_counter()\n",
    "        fwd_dt = t3 - t2\n",
    "\n",
    "        if bs_seen is None:\n",
    "            bs_seen = int(images.shape[0])\n",
    "\n",
    "        if bi >= warmup_batches:\n",
    "            fwd_time_sum += fwd_dt\n",
    "            e2e_time_sum += e2e_dt\n",
    "            measured += 1\n",
    "\n",
    "    if measured > 0 and bs_seen:\n",
    "        fwd_t_batch = fwd_time_sum / measured\n",
    "        fwd_t_img   = fwd_t_batch / bs_seen\n",
    "        fwd_fps     = 1.0 / fwd_t_img\n",
    "\n",
    "        e2e_t_batch = e2e_time_sum / measured\n",
    "        e2e_t_img   = e2e_t_batch / bs_seen\n",
    "        e2e_fps     = 1.0 / e2e_t_img\n",
    "    else:\n",
    "        fwd_t_batch = fwd_t_img = fwd_fps = float(\"nan\")\n",
    "        e2e_t_batch = e2e_t_img = e2e_fps = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"fwd_batch_s\": fwd_t_batch,\n",
    "        \"fwd_img_s\": fwd_t_img,\n",
    "        \"fwd_fps\": fwd_fps,\n",
    "        \"e2e_batch_s\": e2e_t_batch,\n",
    "        \"e2e_img_s\": e2e_t_img,\n",
    "        \"e2e_fps\": e2e_fps,\n",
    "        \"batch_size\": bs_seen,\n",
    "        \"measured_batches\": measured,\n",
    "    }\n",
    "\n",
    "# пример запуска (FP32)\n",
    "stats = evaluate_tripy_time(fast_model, test_loader, warmup_batches=5, fp16=False)\n",
    "print(f\"TriPy FP32: \"\n",
    "      f\"forward: {stats['fwd_batch_s']*1000:.3f} ms/batch, {stats['fwd_img_s']*1000:.4f} ms/img, {stats['fwd_fps']:.1f} FPS | \"\n",
    "      f\"e2e: {stats['e2e_batch_s']*1000:.3f} ms/batch, {stats['e2e_img_s']*1000:.4f} ms/img, {stats['e2e_fps']:.1f} FPS\")\n"
   ],
   "id": "fadb3d454d52ed43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriPy FP32: forward: 0.533 ms/batch, 0.0005 ms/img, 1877376.5 FPS | e2e: 1.466 ms/batch, 0.0015 ms/img, 682332.6 FPS\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
