{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-08T15:16:37.138182Z",
     "start_time": "2025-11-08T15:16:35.178907Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.out = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = t.reshape(-1, 16 * 5 * 5)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.out(t)\n",
    "        return t"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T15:16:49.364691Z",
     "start_time": "2025-11-08T15:16:38.173888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=200,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ],
   "id": "d68520ab99723538",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T15:16:51.080556Z",
     "start_time": "2025-11-08T15:16:51.014393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = LeNet().to(device)\n",
    "torch.save(model.state_dict(), \"lenet_init_state.pth\")\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.05,\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4,\n",
    ")\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "num_epochs = 60\n",
    "best_acc = 0.0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in data_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc"
   ],
   "id": "4c27a140126806d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T15:30:31.417570Z",
     "start_time": "2025-11-08T15:16:54.516355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        total += labels.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, test_loader, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{num_epochs}] \"\n",
    "        f\"train_loss={train_loss:.4f} train_acc={train_acc:.4f} \"\n",
    "        f\"val_loss={val_loss:.4f} val_acc={val_acc:.4f} \"\n",
    "        f\"lr={scheduler.get_last_lr()[0]:.5f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"lenet_cifar10_best_pytorch.pth\")\n",
    "        print(f\"  -> new best model saved (val_acc={best_acc:.4f})\")\n"
   ],
   "id": "c49d3a8e01125a96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60] train_loss=1.8535 train_acc=0.3092 val_loss=1.5341 val_acc=0.4452 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.4452)\n",
      "Epoch [2/60] train_loss=1.5643 train_acc=0.4292 val_loss=1.4005 val_acc=0.4923 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.4923)\n",
      "Epoch [3/60] train_loss=1.4619 train_acc=0.4746 val_loss=1.3780 val_acc=0.5003 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.5003)\n",
      "Epoch [4/60] train_loss=1.4076 train_acc=0.4950 val_loss=1.2948 val_acc=0.5418 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.5418)\n",
      "Epoch [5/60] train_loss=1.3576 train_acc=0.5156 val_loss=1.2279 val_acc=0.5722 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.5722)\n",
      "Epoch [6/60] train_loss=1.3263 train_acc=0.5289 val_loss=1.2295 val_acc=0.5750 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.5750)\n",
      "Epoch [7/60] train_loss=1.2965 train_acc=0.5410 val_loss=1.2435 val_acc=0.5602 lr=0.05000\n",
      "Epoch [8/60] train_loss=1.2679 train_acc=0.5525 val_loss=1.1958 val_acc=0.5853 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.5853)\n",
      "Epoch [9/60] train_loss=1.2646 train_acc=0.5538 val_loss=1.1468 val_acc=0.6041 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6041)\n",
      "Epoch [10/60] train_loss=1.2429 train_acc=0.5610 val_loss=1.1549 val_acc=0.5989 lr=0.05000\n",
      "Epoch [11/60] train_loss=1.2243 train_acc=0.5672 val_loss=1.1338 val_acc=0.6047 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6047)\n",
      "Epoch [12/60] train_loss=1.2115 train_acc=0.5753 val_loss=1.0874 val_acc=0.6236 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6236)\n",
      "Epoch [13/60] train_loss=1.1991 train_acc=0.5791 val_loss=1.1139 val_acc=0.6181 lr=0.05000\n",
      "Epoch [14/60] train_loss=1.2068 train_acc=0.5780 val_loss=1.1398 val_acc=0.6117 lr=0.05000\n",
      "Epoch [15/60] train_loss=1.1915 train_acc=0.5835 val_loss=1.1063 val_acc=0.6285 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6285)\n",
      "Epoch [16/60] train_loss=1.1827 train_acc=0.5881 val_loss=1.1191 val_acc=0.6102 lr=0.05000\n",
      "Epoch [17/60] train_loss=1.1663 train_acc=0.5917 val_loss=1.1091 val_acc=0.6176 lr=0.05000\n",
      "Epoch [18/60] train_loss=1.1690 train_acc=0.5922 val_loss=1.0614 val_acc=0.6336 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6336)\n",
      "Epoch [19/60] train_loss=1.1656 train_acc=0.5940 val_loss=1.1286 val_acc=0.6113 lr=0.05000\n",
      "Epoch [20/60] train_loss=1.1660 train_acc=0.5948 val_loss=1.0930 val_acc=0.6197 lr=0.05000\n",
      "Epoch [21/60] train_loss=1.1567 train_acc=0.5991 val_loss=1.0507 val_acc=0.6344 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6344)\n",
      "Epoch [22/60] train_loss=1.1354 train_acc=0.6051 val_loss=1.0365 val_acc=0.6390 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6390)\n",
      "Epoch [23/60] train_loss=1.1329 train_acc=0.6049 val_loss=1.0768 val_acc=0.6274 lr=0.05000\n",
      "Epoch [24/60] train_loss=1.1406 train_acc=0.6021 val_loss=1.0229 val_acc=0.6514 lr=0.05000\n",
      "  -> new best model saved (val_acc=0.6514)\n",
      "Epoch [25/60] train_loss=1.1351 train_acc=0.6026 val_loss=1.0918 val_acc=0.6202 lr=0.05000\n",
      "Epoch [26/60] train_loss=1.1322 train_acc=0.6063 val_loss=1.0249 val_acc=0.6415 lr=0.05000\n",
      "Epoch [27/60] train_loss=1.1353 train_acc=0.6056 val_loss=1.0421 val_acc=0.6411 lr=0.05000\n",
      "Epoch [28/60] train_loss=1.1252 train_acc=0.6084 val_loss=1.0299 val_acc=0.6397 lr=0.05000\n",
      "Epoch [29/60] train_loss=1.1187 train_acc=0.6112 val_loss=1.0810 val_acc=0.6306 lr=0.05000\n",
      "Epoch [30/60] train_loss=1.1296 train_acc=0.6062 val_loss=1.1148 val_acc=0.6151 lr=0.00500\n",
      "Epoch [31/60] train_loss=0.9823 train_acc=0.6571 val_loss=0.8991 val_acc=0.6916 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.6916)\n",
      "Epoch [32/60] train_loss=0.9437 train_acc=0.6710 val_loss=0.8760 val_acc=0.6988 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.6988)\n",
      "Epoch [33/60] train_loss=0.9201 train_acc=0.6805 val_loss=0.8669 val_acc=0.7033 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7033)\n",
      "Epoch [34/60] train_loss=0.9159 train_acc=0.6798 val_loss=0.8622 val_acc=0.7042 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7042)\n",
      "Epoch [35/60] train_loss=0.9025 train_acc=0.6847 val_loss=0.8589 val_acc=0.7047 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7047)\n",
      "Epoch [36/60] train_loss=0.9005 train_acc=0.6851 val_loss=0.8524 val_acc=0.7032 lr=0.00500\n",
      "Epoch [37/60] train_loss=0.8857 train_acc=0.6890 val_loss=0.8522 val_acc=0.7073 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7073)\n",
      "Epoch [38/60] train_loss=0.8926 train_acc=0.6874 val_loss=0.8431 val_acc=0.7098 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7098)\n",
      "Epoch [39/60] train_loss=0.8885 train_acc=0.6905 val_loss=0.8333 val_acc=0.7154 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7154)\n",
      "Epoch [40/60] train_loss=0.8793 train_acc=0.6912 val_loss=0.8426 val_acc=0.7113 lr=0.00500\n",
      "Epoch [41/60] train_loss=0.8754 train_acc=0.6934 val_loss=0.8263 val_acc=0.7148 lr=0.00500\n",
      "Epoch [42/60] train_loss=0.8688 train_acc=0.6986 val_loss=0.8294 val_acc=0.7173 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7173)\n",
      "Epoch [43/60] train_loss=0.8636 train_acc=0.6980 val_loss=0.8272 val_acc=0.7184 lr=0.00500\n",
      "  -> new best model saved (val_acc=0.7184)\n",
      "Epoch [44/60] train_loss=0.8608 train_acc=0.6983 val_loss=0.8198 val_acc=0.7179 lr=0.00500\n",
      "Epoch [45/60] train_loss=0.8596 train_acc=0.6997 val_loss=0.8224 val_acc=0.7185 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7185)\n",
      "Epoch [46/60] train_loss=0.8432 train_acc=0.7048 val_loss=0.8090 val_acc=0.7224 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7224)\n",
      "Epoch [47/60] train_loss=0.8394 train_acc=0.7084 val_loss=0.8061 val_acc=0.7238 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7238)\n",
      "Epoch [48/60] train_loss=0.8356 train_acc=0.7068 val_loss=0.8052 val_acc=0.7235 lr=0.00050\n",
      "Epoch [49/60] train_loss=0.8370 train_acc=0.7083 val_loss=0.8037 val_acc=0.7224 lr=0.00050\n",
      "Epoch [50/60] train_loss=0.8327 train_acc=0.7095 val_loss=0.8050 val_acc=0.7237 lr=0.00050\n",
      "Epoch [51/60] train_loss=0.8319 train_acc=0.7069 val_loss=0.8029 val_acc=0.7242 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7242)\n",
      "Epoch [52/60] train_loss=0.8343 train_acc=0.7081 val_loss=0.8040 val_acc=0.7246 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7246)\n",
      "Epoch [53/60] train_loss=0.8309 train_acc=0.7093 val_loss=0.8006 val_acc=0.7248 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7248)\n",
      "Epoch [54/60] train_loss=0.8241 train_acc=0.7129 val_loss=0.8000 val_acc=0.7250 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7250)\n",
      "Epoch [55/60] train_loss=0.8339 train_acc=0.7084 val_loss=0.8020 val_acc=0.7252 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7252)\n",
      "Epoch [56/60] train_loss=0.8319 train_acc=0.7104 val_loss=0.8033 val_acc=0.7252 lr=0.00050\n",
      "Epoch [57/60] train_loss=0.8267 train_acc=0.7118 val_loss=0.7993 val_acc=0.7250 lr=0.00050\n",
      "Epoch [58/60] train_loss=0.8328 train_acc=0.7079 val_loss=0.7994 val_acc=0.7270 lr=0.00050\n",
      "  -> new best model saved (val_acc=0.7270)\n",
      "Epoch [59/60] train_loss=0.8249 train_acc=0.7099 val_loss=0.7997 val_acc=0.7233 lr=0.00050\n",
      "Epoch [60/60] train_loss=0.8262 train_acc=0.7109 val_loss=0.8010 val_acc=0.7256 lr=0.00050\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
