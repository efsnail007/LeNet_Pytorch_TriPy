{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T07:28:32.957267Z",
     "start_time": "2025-12-14T07:28:31.911507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=200,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ],
   "id": "64b99b81a7f2ac1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T07:28:37.969671Z",
     "start_time": "2025-12-14T07:28:32.969924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.out = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2, 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2, 2)\n",
    "        x = x.reshape(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_pytorch_fp32(model, test_loader, warmup_batches=5, device=\"cuda\"):\n",
    "    model.eval().to(device).float()         # чистый FP32, без autocast\n",
    "    total = correct = 0\n",
    "    run_loss = 0.0\n",
    "\n",
    "    fwd_time_sum = 0.0     # только forward (данные уже на GPU)\n",
    "    e2e_time_sum = 0.0     # H2D -> forward -> sync\n",
    "    measured = 0\n",
    "    bs_seen = None\n",
    "\n",
    "    for bi, (images_cpu, labels_cpu) in enumerate(test_loader):\n",
    "        # --- end-to-end замер ---\n",
    "        torch.cuda.synchronize()\n",
    "        t0 = time.perf_counter()\n",
    "        images = images_cpu.to(device, non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "        e2e_dt = t1 - t0\n",
    "\n",
    "        # --- forward-only замер ---\n",
    "        # данные уже на GPU, меряем только compute\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.perf_counter()\n",
    "        _ = model(images)\n",
    "        torch.cuda.synchronize()\n",
    "        t3 = time.perf_counter()\n",
    "        fwd_dt = t3 - t2\n",
    "\n",
    "        labels = labels_cpu.to(device, non_blocking=True)\n",
    "        loss = criterion(outputs, labels)\n",
    "        run_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        if bs_seen is None:\n",
    "            bs_seen = labels.size(0)\n",
    "\n",
    "        if bi >= warmup_batches:\n",
    "            fwd_time_sum += fwd_dt\n",
    "            e2e_time_sum += e2e_dt\n",
    "            measured += 1\n",
    "\n",
    "    avg_loss = run_loss / total\n",
    "    acc = correct / total\n",
    "\n",
    "    if measured > 0 and bs_seen:\n",
    "        fwd_t_batch = fwd_time_sum / measured\n",
    "        fwd_t_img   = fwd_t_batch / bs_seen\n",
    "        fwd_fps     = 1.0 / fwd_t_img\n",
    "\n",
    "        e2e_t_batch = e2e_time_sum / measured\n",
    "        e2e_t_img   = e2e_t_batch / bs_seen\n",
    "        e2e_fps     = 1.0 / e2e_t_img\n",
    "    else:\n",
    "        fwd_t_batch = fwd_t_img = fwd_fps = float(\"nan\")\n",
    "        e2e_t_batch = e2e_t_img = e2e_fps = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"loss\": avg_loss,\n",
    "        \"acc\": acc,\n",
    "        \"fwd_batch_s\": fwd_t_batch,\n",
    "        \"fwd_img_s\": fwd_t_img,\n",
    "        \"fwd_fps\": fwd_fps,\n",
    "        \"e2e_batch_s\": e2e_t_batch,\n",
    "        \"e2e_img_s\": e2e_t_img,\n",
    "        \"e2e_fps\": e2e_fps,\n",
    "    }\n",
    "\n",
    "# пример запуска\n",
    "model = LeNet()\n",
    "model.load_state_dict(torch.load(\"lenet_cifar10_best_pytorch.pth\", map_location=\"cpu\"))\n",
    "stats = evaluate_pytorch_fp32(model, test_loader)\n",
    "print(f\"PyTorch FP32: loss={stats['loss']:.4f} acc={stats['acc']:.4f} | \"\n",
    "      f\"forward: {stats['fwd_batch_s']*1000:.3f} ms/batch, {stats['fwd_img_s']*1000:.4f} ms/img, {stats['fwd_fps']:.1f} FPS | \"\n",
    "      f\"e2e: {stats['e2e_batch_s']*1000:.3f} ms/batch, {stats['e2e_img_s']*1000:.4f} ms/img, {stats['e2e_fps']:.1f} FPS\")\n"
   ],
   "id": "fe3aac805bd9c202",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch FP32: loss=0.7994 acc=0.7270 | forward: 2.020 ms/batch, 0.0101 ms/img, 98991.1 FPS | e2e: 3.551 ms/batch, 0.0178 ms/img, 56327.1 FPS\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
